{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11ebb65a-ba2e-4234-8841-b2777b69472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pyreft\n",
    "\n",
    "def apply_chat_template(row):\n",
    "    messages = [{\"role\": \"user\", \"content\": row[\"input\"]}]\n",
    "    nobos = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True)[1:]\n",
    "    return tokenizer.decode(nobos)\n",
    "\n",
    "def prepare_df(original_df, tokenizer):\n",
    "    original_df['input'] = original_df.apply(apply_chat_template, axis=1)\n",
    "    return original_df # do nothing, the task will be standard instruction tuning.\n",
    "\n",
    "def apply_zeroshot_prompt_template(\n",
    "    qID,\n",
    "    wave=\"Pew_American_Trends_Panel_disagreement_500\", \n",
    "    demographic_group=\"POLPARTY\",\n",
    "    demographic=\"Democrat\",\n",
    "    output_type=\"model_logprobs\",\n",
    "    provide_ground_truth_distribution=False\n",
    "):\n",
    "    data_path = '{}/opinions_qa/data/human_resp/'.format(os.getcwd())\n",
    "    demographic_in_prompt = demographic\n",
    "    data = json.load(open(data_path + wave + '/' + demographic_group + \"_data.json\"))\n",
    "    prompt = \"Your task is to simulate an answer to a new question from the group of {}s. \".format(demographic_in_prompt, demographic_in_prompt)\n",
    "\n",
    "    if output_type=='sequence':\n",
    "        prompt+= 'After the examples, please simulate 30 samples from a group of {} for the new question asked. Please only respond with 30 multiple choice answers, no extra spaces, characters, quotes or text. Please only produce 30 characters. Answers with more than 30 characters will not be accepted.'.format(demographic_in_prompt)\n",
    "    elif output_type=='model_logprobs': \n",
    "        prompt += 'After the examples, please simulate an answer from a group of \"{}\" for the question asked. Please only respond with a single multiple choice answer, no extra spaces, characters, quotes or text. Please only produce 1 character. Answers with more than one characters will not be accepted.'.format(demographic_in_prompt)\n",
    "    elif output_type=='express_distribution': \n",
    "        prompt += 'After the examples, please express the distribution of answers from a group of \"{}\" for the question asked. Please only respond in the exact format of a dictionary mapping answer choice letter to probability, no extra spaces, characters, quotes or text. Please only produce 1 sentence in this format. Answers outside of this format will not be accepted.'.format(demographic_in_prompt)\n",
    "    example_input = prompt + \"\\nQuestion: \" + question + \"?\\n\"\n",
    "    n = (sum(data[qID][demographic].values()))\n",
    "    MC_options = list(data[qID][demographic].keys())\n",
    "    for i, option in enumerate(MC_options):\n",
    "        example_input +=\"{}. {}. \".format(options[i], option)\n",
    "    \n",
    "    return example_input\n",
    "    \n",
    "def get_test_questions_with_distributions(\n",
    "    seen_qIDs,\n",
    "    wave=\"Pew_American_Trends_Panel_disagreement_500\", \n",
    "    demographic_group=\"POLPARTY\",\n",
    "    demographic=\"Democrat\",\n",
    "):\n",
    "    data_path = '{}/opinions_qa/data/human_resp/'.format(os.getcwd())\n",
    "    demographic_in_prompt = demographic\n",
    "    data = json.load(open(data_path + wave + '/' + demographic_group + \"_data.json\"))\n",
    "    filtered_data = {}\n",
    "    for k, v in data.items():\n",
    "        if k in seen_qIDs:\n",
    "            continue\n",
    "        filtered_data[k] = v\n",
    "    return filtered_data\n",
    "\n",
    "def parse_answers(raw_response, available_choices):\n",
    "    if \"Answer:\" not in raw_response:\n",
    "        print(\"Warning: Input string does not contain 'Answer:'.\")\n",
    "        return None\n",
    "    answers_part = raw_response.split(\"Answer:\")[1]\n",
    "    answers_list = answers_part.strip().split()\n",
    "    counts = {choice: 0 for choice in available_choices}\n",
    "    total_answers = 0\n",
    "    for answer in answers_list:\n",
    "        if answer in available_choices:\n",
    "            counts[answer] += 1\n",
    "            total_answers += 1\n",
    "        else:\n",
    "            # Optionally, handle invalid choices here\n",
    "            pass\n",
    "    probabilities = {choice: count / total_answers for choice, count in counts.items()}\n",
    "    return counts, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8fd8d5-5e22-4ed0-92bc-fd70f70b41ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6596325e5945149ab3ebb6ba07a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e595e570aaf8474097f2710456904974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, pyreft\n",
    "device = \"cuda\"\n",
    "\n",
    "model_name_or_path = \"google/gemma-2-2b-it\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=torch.bfloat16, device_map=device)\n",
    "\n",
    "# get tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path, model_max_length=2048, \n",
    "    padding_side=\"right\", use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c7396-7dcb-405c-989a-075a076150e5",
   "metadata": {},
   "source": [
    "#### Getting a random qID and the corresponding training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b741c167-cd80-4cfa-8d58-15537c59c6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>qID</th>\n",
       "      <th>icl_qID</th>\n",
       "      <th>demographic_group</th>\n",
       "      <th>demographic</th>\n",
       "      <th>output_type</th>\n",
       "      <th>wave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\nYour task is to simulate ...</td>\n",
       "      <td>Answer: A A A D D D A B A A C A A C C A C D A ...</td>\n",
       "      <td>ECON5_d_W54</td>\n",
       "      <td>INEQ5_f_W54</td>\n",
       "      <td>POLPARTY</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>sequence</td>\n",
       "      <td>Pew_American_Trends_Panel_disagreement_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\nYour task is to simulate ...</td>\n",
       "      <td>Answer: D C D B C D C D C D A A A A A A A C B ...</td>\n",
       "      <td>ECON5_d_W54</td>\n",
       "      <td>INEQ5_f_W54</td>\n",
       "      <td>POLPARTY</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>sequence</td>\n",
       "      <td>Pew_American_Trends_Panel_disagreement_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\nYour task is to simulate ...</td>\n",
       "      <td>Answer: C C D D D A A B A A D D B D B D B A A ...</td>\n",
       "      <td>ECON5_d_W54</td>\n",
       "      <td>INEQ5_f_W54</td>\n",
       "      <td>POLPARTY</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>sequence</td>\n",
       "      <td>Pew_American_Trends_Panel_disagreement_100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  <start_of_turn>user\\nYour task is to simulate ...   \n",
       "1  <start_of_turn>user\\nYour task is to simulate ...   \n",
       "2  <start_of_turn>user\\nYour task is to simulate ...   \n",
       "\n",
       "                                              output          qID  \\\n",
       "0  Answer: A A A D D D A B A A C A A C C A C D A ...  ECON5_d_W54   \n",
       "1  Answer: D C D B C D C D C D A A A A A A A C B ...  ECON5_d_W54   \n",
       "2  Answer: C C D D D A A B A A D D B D B D B A A ...  ECON5_d_W54   \n",
       "\n",
       "       icl_qID demographic_group demographic output_type  \\\n",
       "0  INEQ5_f_W54          POLPARTY    Democrat    sequence   \n",
       "1  INEQ5_f_W54          POLPARTY    Democrat    sequence   \n",
       "2  INEQ5_f_W54          POLPARTY    Democrat    sequence   \n",
       "\n",
       "                                         wave  \n",
       "0  Pew_American_Trends_Panel_disagreement_100  \n",
       "1  Pew_American_Trends_Panel_disagreement_100  \n",
       "2  Pew_American_Trends_Panel_disagreement_100  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_group = \"POLPARTY\"\n",
    "demographic = \"Democrat\"\n",
    "output_type = \"sequence\"\n",
    "\n",
    "qIDs, waves = get_q_IDs_opinionqa()\n",
    "raw_dataset = get_few_shot_training_examples(\n",
    "    qIDs[0],\n",
    "    wave=\"Pew_American_Trends_Panel_disagreement_100\", \n",
    "    demographic_group=\"POLPARTY\",\n",
    "    demographic=\"Democrat\",\n",
    "    output_type=\"sequence\", \n",
    "    dataset=\"opinionqa\",\n",
    "    n_shots=5,\n",
    "    n_simulations_per_shot=5,\n",
    ")\n",
    "training_dataset = prepare_df(raw_dataset.copy(), tokenizer)\n",
    "training_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "778a8c38-4325-440f-8ea1-a5cf82099c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable intervention params: 18,436 || trainable model params: 0\n",
      "model params: 2,614,341,888 || trainable%: 0.0007051870332882797\n"
     ]
    }
   ],
   "source": [
    "# get reft model\n",
    "reft_config = pyreft.ReftConfig(representations={\n",
    "    \"layer\": 20, \"component\": \"block_output\",\n",
    "    \"low_rank_dimension\": 4,\n",
    "    \"intervention\": pyreft.LoreftIntervention(embed_dim=model.config.hidden_size,\n",
    "    low_rank_dimension=4)})\n",
    "reft_model = pyreft.get_reft_model(model, reft_config)\n",
    "reft_model.set_device(\"cuda\")\n",
    "reft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4098572a-c384-44cb-8d9a-a9344ade19c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 00:39, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.681100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.267700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.041700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/checkpoint-300/intervenable_model' already exists.\n"
     ]
    }
   ],
   "source": [
    "# prepare training data modules\n",
    "data_module = pyreft.make_last_position_supervised_data_module(\n",
    "    tokenizer, model, [input for input in training_dataset.input], \n",
    "    [output for output in training_dataset.output], nonstop=False)\n",
    "\n",
    "# train\n",
    "training_args = transformers.TrainingArguments(\n",
    "    num_train_epochs=100.0, output_dir=\"./tmp\", per_device_train_batch_size=10, \n",
    "    learning_rate=1e-3, logging_steps=40, report_to=[])\n",
    "trainer = pyreft.ReftTrainerForCausalLM(\n",
    "    model=reft_model, tokenizer=tokenizer, args=training_args, **data_module)\n",
    "_ = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "89bc5d68-163e-4c55-9110-4bd00e511233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing qID: ECON5_d_W54\n",
      "Golden dist:\n",
      "{'A': 0.06757843925985518, 'B': 0.02172164119066774, 'C': 0.12389380530973451, 'D': 0.7393403057119872, 'E': 0.0418342719227675, 'F': 0.0056315366049879325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/wuzhengx/ipykernel_168799/3763360466.py:4: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  test_qID = random.sample(test_pool.keys(), 1)[0]\n"
     ]
    }
   ],
   "source": [
    "test_pool = get_test_questions_with_distributions(\n",
    "    seen_qIDs=set(training_dataset.qID).union(training_dataset.icl_qID)\n",
    ")\n",
    "test_qID = random.sample(test_pool.keys(), 1)[0]\n",
    "test_qID = \"ECON5_d_W54\"\n",
    "print(\"testing qID:\", test_qID)\n",
    "n = (sum(test_pool[test_qID][demographic].values()))\n",
    "MC_options = list(test_pool[test_qID][demographic].keys())\n",
    "all_options, probs = [], []\n",
    "for i, option in enumerate(MC_options):\n",
    "    all_options.append(options[i])\n",
    "    probs.append(test_pool[test_qID][demographic][option]/n)\n",
    "golden_dist = dict(zip(all_options, probs))\n",
    "print(\"Golden dist:\")\n",
    "print(golden_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "14b6034d-2134-4f03-a590-7234c553f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: D E A F F F A A A C C A A C C F F B F F C C\n",
      "Predicted dist:\n",
      "{'A': 0.2727272727272727, 'B': 0.045454545454545456, 'C': 0.2727272727272727, 'D': 0.045454545454545456, 'E': 0.045454545454545456, 'F': 0.3181818181818182}\n"
     ]
    }
   ],
   "source": [
    "instruction = apply_zeroshot_prompt_template(test_qID, output_type=\"sequence\")\n",
    "instruction = apply_chat_template({\"input\": instruction})\n",
    "prompt = tokenizer(instruction, return_tensors=\"pt\").to(device)\n",
    "base_unit_location = prompt[\"input_ids\"].shape[-1] - 1  # last position\n",
    "_, reft_response = reft_model.generate(\n",
    "    prompt, unit_locations={\"sources->base\": (None, [[[base_unit_location]]])},\n",
    "    intervene_on_prompt=True, max_new_tokens=36, do_sample=True, \n",
    "    eos_token_id=tokenizer.eos_token_id, early_stopping=True\n",
    ")\n",
    "response = tokenizer.decode(reft_response[0][prompt[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "print(response)\n",
    "counts, probabilities = parse_answers(response, golden_dist.keys())\n",
    "print(\"Predicted dist:\")\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}